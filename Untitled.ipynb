{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".DS_Store\n",
      "top_image_00000.png\n",
      "top_image_00001.png\n",
      "top_image_00002.png\n",
      "top_image_00003.png\n",
      "top_image_00004.png\n",
      "top_image_00005.png\n",
      "top_image_00006.png\n",
      "top_image_00007.png\n",
      "top_image_00008.png\n",
      "top_image_00009.png\n",
      "top_image_00010.png\n",
      "top_image_00011.png\n",
      "top_image_00012.png\n",
      "top_image_00013.png\n",
      "top_image_00014.png\n",
      "top_image_00015.png\n",
      "top_image_00016.png\n",
      "top_image_00017.png\n",
      "top_image_00018.png\n",
      "top_image_00019.png\n",
      "top_image_00020.png\n",
      "top_image_00021.png\n",
      "top_image_00022.png\n",
      "top_image_00023.png\n",
      "top_image_00024.png\n",
      "top_image_00025.png\n",
      "top_image_00026.png\n",
      "top_image_00027.png\n",
      "top_image_00028.png\n",
      "top_image_00029.png\n",
      "top_image_00030.png\n",
      "top_image_00031.png\n",
      "top_image_00032.png\n",
      "top_image_00033.png\n",
      "top_image_00034.png\n",
      "top_image_00035.png\n",
      "top_image_00036.png\n",
      "top_image_00037.png\n",
      "top_image_00038.png\n",
      "top_image_00039.png\n",
      "top_image_00040.png\n",
      "top_image_00041.png\n",
      "top_image_00042.png\n",
      "top_image_00043.png\n",
      "top_image_00044.png\n",
      "top_image_00045.png\n",
      "top_image_00046.png\n",
      "top_image_00047.png\n",
      "top_image_00048.png\n",
      "top_image_00049.png\n",
      "top_image_00050.png\n",
      "top_image_00051.png\n",
      "top_image_00052.png\n",
      "top_image_00053.png\n",
      "top_image_00054.png\n",
      "top_image_00055.png\n",
      "top_image_00056.png\n",
      "top_image_00057.png\n",
      "top_image_00058.png\n",
      "top_image_00059.png\n",
      "top_image_00060.png\n",
      "top_image_00061.png\n",
      "top_image_00062.png\n",
      "top_image_00063.png\n",
      "top_image_00064.png\n",
      "top_image_00065.png\n",
      "top_image_00066.png\n",
      "top_image_00067.png\n",
      "top_image_00068.png\n",
      "top_image_00069.png\n",
      "top_image_00070.png\n",
      "top_image_00071.png\n",
      "top_image_00072.png\n",
      "top_image_00073.png\n",
      "top_image_00074.png\n",
      "top_image_00075.png\n",
      "top_image_00076.png\n",
      "top_image_00077.png\n",
      "top_image_00078.png\n",
      "top_image_00079.png\n",
      "top_image_00080.png\n",
      "top_image_00081.png\n",
      "top_image_00082.png\n",
      "top_image_00083.png\n",
      "top_image_00084.png\n",
      "top_image_00085.png\n",
      "top_image_00086.png\n",
      "top_image_00087.png\n",
      "top_image_00088.png\n",
      "top_image_00089.png\n",
      "top_image_00090.png\n",
      "top_image_00091.png\n",
      "top_image_00092.png\n",
      "top_image_00093.png\n",
      "top_image_00094.png\n",
      "top_image_00095.png\n",
      "top_image_00096.png\n",
      "top_image_00097.png\n",
      "top_image_00098.png\n",
      "top_image_00099.png\n",
      "top_image_00100.png\n",
      "top_image_00101.png\n",
      "top_image_00102.png\n",
      "top_image_00103.png\n",
      "top_image_00104.png\n",
      "top_image_00105.png\n",
      "top_image_00106.png\n",
      "top_image_00107.png\n",
      "top_image_00108.png\n",
      "top_image_00109.png\n",
      "top_image_00110.png\n",
      "top_image_00111.png\n",
      "top_image_00112.png\n",
      "top_image_00113.png\n",
      "top_image_00114.png\n",
      "top_image_00115.png\n",
      "top_image_00116.png\n",
      "top_image_00117.png\n",
      "top_image_00118.png\n",
      "top_image_00119.png\n",
      "top_image_00120.png\n",
      "top_image_00121.png\n",
      "top_image_00122.png\n",
      "top_image_00123.png\n",
      "top_image_00124.png\n",
      "top_image_00125.png\n",
      "top_image_00126.png\n",
      "top_image_00127.png\n",
      "top_image_00128.png\n",
      "top_image_00129.png\n",
      "top_image_00130.png\n",
      "top_image_00131.png\n",
      "top_image_00132.png\n",
      "top_image_00133.png\n",
      "top_image_00134.png\n",
      "top_image_00135.png\n",
      "top_image_00136.png\n",
      "top_image_00137.png\n",
      "top_image_00138.png\n",
      "top_image_00139.png\n",
      "top_image_00140.png\n",
      "top_image_00141.png\n",
      "top_image_00142.png\n",
      "top_image_00143.png\n",
      "top_image_00144.png\n",
      "top_image_00145.png\n",
      "top_image_00146.png\n",
      "top_image_00147.png\n",
      "top_image_00148.png\n",
      "top_image_00149.png\n",
      "top_image_00150.png\n",
      "top_image_00151.png\n",
      "top_image_00152.png\n",
      "top_image_00153.png\n",
      "top_image_00154.png\n",
      "top_image_00155.png\n",
      "top_image_00156.png\n",
      "top_image_00157.png\n",
      "top_image_00158.png\n",
      "top_image_00159.png\n",
      "top_image_00160.png\n",
      "top_image_00161.png\n",
      "top_image_00162.png\n",
      "top_image_00163.png\n",
      "top_image_00164.png\n",
      "top_image_00165.png\n",
      "top_image_00166.png\n",
      "top_image_00167.png\n",
      "top_image_00168.png\n",
      "top_image_00169.png\n",
      "top_image_00170.png\n",
      "top_image_00171.png\n",
      "top_image_00172.png\n",
      "top_image_00173.png\n",
      "top_image_00174.png\n",
      "top_image_00175.png\n",
      "top_image_00176.png\n",
      "top_image_00177.png\n",
      "top_image_00178.png\n",
      "top_image_00179.png\n",
      "top_image_00180.png\n",
      "top_image_00181.png\n",
      "top_image_00182.png\n",
      "top_image_00183.png\n",
      "top_image_00184.png\n",
      "top_image_00185.png\n",
      "top_image_00186.png\n",
      "top_image_00187.png\n",
      "top_image_00188.png\n",
      "top_image_00189.png\n",
      "top_image_00190.png\n",
      "top_image_00191.png\n",
      "top_image_00192.png\n",
      "top_image_00193.png\n",
      "top_image_00194.png\n",
      "top_image_00195.png\n",
      "top_image_00196.png\n",
      "top_image_00197.png\n",
      "top_image_00198.png\n",
      "top_image_00199.png\n",
      "top_image_00200.png\n",
      "top_image_00201.png\n",
      "top_image_00202.png\n",
      "top_image_00203.png\n",
      "top_image_00204.png\n",
      "top_image_00205.png\n",
      "top_image_00206.png\n",
      "top_image_00207.png\n",
      "top_image_00208.png\n",
      "top_image_00209.png\n",
      "top_image_00210.png\n",
      "top_image_00211.png\n",
      "top_image_00212.png\n",
      "top_image_00213.png\n",
      "top_image_00214.png\n",
      "top_image_00215.png\n",
      "top_image_00216.png\n",
      "top_image_00217.png\n",
      "top_image_00218.png\n",
      "top_image_00219.png\n",
      "top_image_00220.png\n",
      "top_image_00221.png\n",
      "top_image_00222.png\n",
      "top_image_00223.png\n",
      "top_image_00224.png\n",
      "top_image_00225.png\n",
      "top_image_00226.png\n",
      "top_image_00227.png\n",
      "top_image_00228.png\n",
      "top_image_00229.png\n",
      "top_image_00230.png\n",
      "top_image_00231.png\n",
      "top_image_00232.png\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import re\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Script config\n",
    "RESIZE_IMAGE = True  # resize the images and write to 'resized_images/'\n",
    "GRAYSCALE = True  # convert image to grayscale? this option is only valid if RESIZE_IMAGE==True (FIXME)\n",
    "TARGET_W, TARGET_H = 300, 300  # 1.74 is weighted avg ratio, but 1.65 aspect ratio is close enough (1.65 was for stop signs)\n",
    "\n",
    "###########################\n",
    "# Execute main script\n",
    "###########################\n",
    "\n",
    "# First get mapping from sign name string to integer label\n",
    "sign_map = {'Car': 1, 'Van': 2, 'Track':3 }  # only 2 sign classes (background class is 0)\n",
    "# '''\n",
    "# sign_map = {}  # sign_name -> integer_label\n",
    "# with open('signnames.csv', 'r') as f:\n",
    "# \tfor line in f:\n",
    "# \t\tline = line[:-1]  # strip newline at the end\n",
    "# \t\tinteger_label, sign_name = line.split(',')\n",
    "# \t\tsign_map[sign_name] = int(integer_label)\n",
    "# '''\n",
    "\n",
    "# Create raw data pickle file\n",
    "data_raw = {}\n",
    "\n",
    "# For speed, put entire contents of mergedAnnotations.csv in memory\n",
    "merged_annotations = []\n",
    "with open('/Users/simin/Desktop/didi-udacity-2017-master/test1.csv', 'r') as f:\n",
    "    for line in f:\n",
    "        line = line[:-1]  # strip trailing newline\n",
    "        merged_annotations.append(line)\n",
    "# print(merged_annotations[0])\n",
    "# Create pickle file to represent dataset\n",
    "# os.mkdir('annotations')\n",
    "image_files = os.listdir('/Users/simin/Desktop/didi-udacity-2017-master/data/seg/top_image')\n",
    "\n",
    "for image_file in image_files:\n",
    "    #print(image_file)\n",
    "    # Find box coordinates for all signs in this image\n",
    "    class_list = []\n",
    "    box_coords_list = []\n",
    "    for line in merged_annotations:\n",
    "        if re.search(image_file, line):\n",
    "            fields = line.split(',')\n",
    "        \n",
    "            # Get sign name and assign class label\n",
    "            sign_name = fields[1]\n",
    "            if sign_name != 'Car' and sign_name != 'Truck' and sign_name !='Van':\n",
    "                continue  # ignore signs that are neither stop nor pedestrianCrossing signs\n",
    "            sign_class = sign_map[sign_name]\n",
    "            class_list.append(sign_class)\n",
    "\n",
    "            # Resize image, get rescaled box coordinates\n",
    "            box_coords = np.array([int(x) for x in fields[2:6]])\n",
    "\n",
    "            if RESIZE_IMAGE:\n",
    "                # Resize the images and write to 'resized_images/'\n",
    "                image = Image.open('annotations/' + image_file)\n",
    "                orig_w, orig_h = image.size\n",
    "\n",
    "                if GRAYSCALE:\n",
    "                    image = image.convert('L')  # 8-bit grayscale\n",
    "                image = image.resize((TARGET_W, TARGET_H), Image.LANCZOS)  # high-quality downsampling filter\n",
    "\n",
    "                resized_dir = 'resized_images_%dx%d/' % (TARGET_W, TARGET_H)\n",
    "                if not os.path.exists(resized_dir):\n",
    "                    os.makedirs(resized_dir)\n",
    "\n",
    "                image.save(os.path.join(resized_dir, image_file))\n",
    "\n",
    "                # Rescale box coordinates\n",
    "                x_scale = TARGET_W / orig_w\n",
    "                y_scale = TARGET_H / orig_h\n",
    "\n",
    "                ulc_x, ulc_y, lrc_x, lrc_y = box_coords\n",
    "                new_box_coords = (ulc_x * x_scale, ulc_y * y_scale, lrc_x * x_scale, lrc_y * y_scale)\n",
    "                new_box_coords = [round(x) for x in new_box_coords]\n",
    "                box_coords = np.array(new_box_coords)\n",
    "\n",
    "            box_coords_list.append(box_coords)\n",
    "\n",
    "    if len(class_list) == 0:\n",
    "        continue  # ignore images with no signs-of-interest\n",
    "    class_list = np.array(class_list)\n",
    "    box_coords_list = np.array(box_coords_list)\n",
    "\n",
    "# Create the list of dicts\n",
    "the_list = []\n",
    "for i in range(len(box_coords_list)):\n",
    "    d = {'class': class_list[i], 'box_coords': box_coords_list[i]}\n",
    "    the_list.append(d)\n",
    "\n",
    "# data_raw[image_file] = the_list\n",
    "\n",
    "# with open('data_raw_%dx%d.p' % (TARGET_W, TARGET_H), 'wb') as f:\n",
    "#     pickle.dump(data_raw, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from setting import*\n",
    "with open('data_raw_%sx%s.p' % (IMG_W, IMG_H), 'rb') as f:\n",
    "    data_raw = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'top_image_00232.png': []}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:IntroToTensorFlow]",
   "language": "python",
   "name": "conda-env-IntroToTensorFlow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
